{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import bs4\n",
    "import time\n",
    "\n",
    "# selenium\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://finance.yahoo.com/quote/<TICK>/sustainability'\n",
    "# replace <TICK> for desired ticker\n",
    "\n",
    "screen_url = 'https://finance.yahoo.com/screener/unsaved/63641ef9-e86c-42c9-b66e-0e9481591369?offset=0&count=100'\n",
    "# url to screener. Contains filter on ESG rating (rating > -1) so that we know ESG data is available for these stocks\n",
    "\n",
    "read_or_scrape_names = 'scrape'\n",
    "# 'scrape' for scraping (takes 2 minutes)\n",
    "# 'read' for reading from previously scraped .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEARCH FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_risk_ratings(soup):\n",
    "    \n",
    "    '''\n",
    "    Reads the ESG Risk Rating, its percentile, and the E, S, and G subratings from a BeautifulSoup-object. \n",
    "    Returns a dict.\n",
    "    '''\n",
    "    \n",
    "    # get total esg score\n",
    "    try:\n",
    "        total_esg_score = soup.find(\"div\", {\"class\":'Fz(36px) Fw(600) D(ib) Mend(5px)'}).get_text()\n",
    "    except:\n",
    "        total_esg_score = 'NA'\n",
    "     \n",
    "    # get percentile of total esg score\n",
    "    try:\n",
    "        total_esg_score_pctile = re.findall(r'\\d+', soup.find(\"span\", {\"class\":\"Bdstarts(s) Bdstartw(0.5px) Pstart(10px) Bdc($seperatorColor) Fz(12px) smartphone_Bd(n) Fw(500)\"}).get_text())[0]\n",
    "    except:    \n",
    "        total_esg_score_pctile = 'NA'\n",
    "        \n",
    "    # get environment risk score\n",
    "    try:\n",
    "        env_risk_score = soup.findAll(\"div\", {\"class\":'D(ib) Fz(23px) smartphone_Fz(22px) Fw(600)'})[0].get_text()\n",
    "    except:\n",
    "        env_risk_score = 'NA'\n",
    "           \n",
    "    # get social risk score\n",
    "    try:\n",
    "        soc_risk_score = soup.findAll(\"div\", {\"class\":'D(ib) Fz(23px) smartphone_Fz(22px) Fw(600)'})[1].get_text()\n",
    "    except:\n",
    "        soc_risk_score = 'NA'\n",
    "        \n",
    "    # get governance risk score\n",
    "    try:\n",
    "        gov_risk_score = soup.findAll(\"div\", {\"class\":'D(ib) Fz(23px) smartphone_Fz(22px) Fw(600)'})[2].get_text()\n",
    "    except:\n",
    "        gov_risk_score = 'NA'\n",
    "\n",
    "    \n",
    "    return {'total_esg_score':total_esg_score, 'total_esg_score_percentile':total_esg_score_pctile, 'environmental_risk_score':env_risk_score, 'social_risk_score':soc_risk_score, 'governance_risk_score':gov_risk_score}\n",
    "\n",
    "def get_controversy_levels(soup):\n",
    "    \n",
    "    '''\n",
    "    Reads the Sustainalytics Controversy Level and the date of latest update from a BeautifulSoup-object. \n",
    "    Returns a dict.\n",
    "    '''\n",
    "        \n",
    "    # get controversy level\n",
    "    try:\n",
    "        controv_level = soup.find(\"div\", {\"class\":\"D(ib) Fz(36px) Fw(500)\"}).get_text()\n",
    "    except:\n",
    "        controv_level = 'NA'\n",
    "    \n",
    "    # get last update date\n",
    "    try:\n",
    "        last_update = soup.find(\"div\", {\"class\":\"Mt(20px) Mb(15px) smartphone_Px(20px) smartphone_Mt(50px) smartphone_Mb(0px)! Fz(12px) C($tertiaryColor)\"}).get_text().split('updated on ')[1]\n",
    "    except:\n",
    "        last_update = 'NA'\n",
    "    \n",
    "    return {'controversy_level':controv_level, 'last_update':last_update}\n",
    "\n",
    "def get_product_involvement(soup):\n",
    "    \n",
    "    '''\n",
    "    Reads product involvement information from a BeautifulSoup-object. \n",
    "    Returns a dict.\n",
    "    '''\n",
    "    \n",
    "    out = {}\n",
    "    \n",
    "    rows = soup.findAll(\"tr\", {\"class\":\"Lh(40px) Bdbs(s) Bdts(s) Bdbw(1px) Bdtw(1px) Bdbc($seperatorColor) Bdtc($seperatorColor)\"})\n",
    "    for row in rows:\n",
    "        try:\n",
    "            product = 'flag_' + row.findAll('span')[0].get_text().lower().replace(' ','_')\n",
    "        except:\n",
    "            product = 'NA'\n",
    "\n",
    "        if row.findAll('span')[1].get_text() == 'Yes':\n",
    "            involve = 1\n",
    "        elif row.findAll('span')[1].get_text() == 'No':\n",
    "            involve = 0\n",
    "        else:\n",
    "            involve = np.NaN\n",
    "            \n",
    "        out[product] = involve\n",
    "    \n",
    "    return out\n",
    "\n",
    "def get_names(soup):\n",
    "    \n",
    "    '''\n",
    "    Reads all stock tickers and associated company names from one page of the Yahoo Finance stock screener in the form of bs4 object.\n",
    "    Returns a list of lists.\n",
    "    '''\n",
    "    \n",
    "    # get all stock tickers\n",
    "    names = soup.findAll(\"tr\", {\"class\":[\"simpTblRow Bgc($hoverBgColor):h BdB Bdbc($seperatorColor) Bdbc($tableBorderBlue):h H(32px) Bgc($lv2BgColor)\", \"simpTblRow Bgc($hoverBgColor):h BdB Bdbc($seperatorColor) Bdbc($tableBorderBlue):h H(32px) Bgc($lv1BgColor)\"]})\n",
    "    \n",
    "    if len(names) > 0:\n",
    "        # iterate over names\n",
    "        out = []\n",
    "        for name in names:\n",
    "            try:\n",
    "                stock_name = name.find(\"td\", {\"aria-label\":\"Name\"}).get_text()\n",
    "            except:\n",
    "                stock_name = 'NA'\n",
    "\n",
    "            try:\n",
    "                stock_tick = name.find(\"a\", {\"class\":\"Fw(600) C($linkColor)\"}).get_text()\n",
    "            except:\n",
    "                stock_tick = 'NA'\n",
    "\n",
    "            out.append([stock_name, stock_tick])\n",
    "            \n",
    "        return out\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('No valid tickers detected in HTML source.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCRAPE STOCK UNIVERSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping 1501 - 1539 of 1539 results...\n"
     ]
    }
   ],
   "source": [
    "if read_or_scrape_names == 'read':\n",
    "    \n",
    "    # read previously scraped tickers\n",
    "    names = pd.read_csv('yahoo_finance_sustainalytics_tickers.csv')\n",
    "\n",
    "elif read_or_scrape_names == 'scrape':\n",
    "    \n",
    "    # open page \n",
    "    screener = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    screener.get(screen_url)\n",
    "    \n",
    "    time.sleep(5) # allow manual consent to cookies\n",
    "    \n",
    "    # get html\n",
    "    html = screener.execute_script(\"return document.body.innerHTML;\")\n",
    "    soup = bs4.BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    # get number of results\n",
    "    n3 = int(soup.find(\"span\", {\"class\":\"Mstart(15px) Fw(500) Fz(s)\"}).get_text().split(' of ')[1].split(' results')[0])          \n",
    "    \n",
    "    # store\n",
    "    outs = []\n",
    "    outs.extend(get_names(soup))\n",
    "    \n",
    "    prev = 0\n",
    "    for n in np.arange(1, nrep+1):\n",
    "    \n",
    "        n1 = n * 100\n",
    "        n2 = min((n + 1) * 100, n3)\n",
    "        \n",
    "        # url of new page to load\n",
    "        screen_url = screen_url.replace(f'offset={prevn}', f'offset={n1}')\n",
    "        \n",
    "        # load new page\n",
    "        screener.get(screen_url)\n",
    "        html = screener.execute_script(\"return document.body.innerHTML;\")\n",
    "        soup = bs4.BeautifulSoup(html, 'lxml')\n",
    "        \n",
    "        # read names\n",
    "        outs.extend(get_names(soup))\n",
    "        \n",
    "        # print info\n",
    "        print(f'Scraping {n1+1} - {n2} of {n3} results...', end='\\r')\n",
    "        \n",
    "        time.sleep(2)\n",
    "        prevn = n1\n",
    "        \n",
    "    names = pd.DataFrame(outs, columns=['CompanyName', 'Ticker'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPEN STOCK DASHBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1539 of 1539: ISSRF (iShares VI Public Limited Company - iShares Edge MSCI EM Minumum Volatility UCITS ETF)\n"
     ]
    }
   ],
   "source": [
    "keys = ['comp_ticker', 'comp_name', 'total_esg_score', 'total_esg_score_percentile', 'environmental_risk_score', 'social_risk_score', 'governance_risk_score', 'controversy_level', 'last_update', 'flag_alcoholic_beverages', 'flag_adult_entertainment', 'flag_gambling', 'flag_tobacco_products', 'flag_animal_testing', 'flag_fur_and_specialty_leather', 'flag_controversial_weapons', 'flag_small_arms', 'flag_catholic_values', 'flag_gmo', 'flag_military_contracting', 'flag_pesticides', 'flag_thermal_coal', 'flag_palm_oil']\n",
    "results = {}\n",
    "for key in keys:\n",
    "    results[key] = []\n",
    "\n",
    "page_open = False\n",
    "for i, row in names.iterrows():\n",
    "    comp_name = row['CompanyName']\n",
    "    comp_tick = row['Ticker']\n",
    "    \n",
    "    # first time opening\n",
    "    if not page_open:\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        driver.get(base_url.replace('<TICK>',comp_tick))\n",
    "        time.sleep(5) # consent to cookies\n",
    "        page_open = True\n",
    "    else:\n",
    "        driver.get(base_url.replace('<TICK>',comp_tick))\n",
    "        \n",
    "    # get html\n",
    "    html = driver.execute_script(\"return document.body.innerHTML;\")\n",
    "    soup = bs4.BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    # get various ESG data\n",
    "    esg = get_risk_ratings(soup)\n",
    "    controv = get_controversy_levels(soup)\n",
    "    prod_inv = get_product_involvement(soup)\n",
    "    \n",
    "    # append data\n",
    "    results['comp_ticker'].append(comp_tick); results['comp_name'].append(comp_name)\n",
    "    \n",
    "    for k, v in esg.items():\n",
    "        results[k].append(v)\n",
    "    \n",
    "    for k, v in controv.items():\n",
    "        results[k].append(v)\n",
    "        \n",
    "    for k, v in prod_inv.items():\n",
    "        results[k].append(v)\n",
    "    \n",
    "    print(f'Reading {i+1} of {len(names)}: {comp_tick} ({comp_name})...', end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame.from_dict(results)\n",
    "res.replace('NA', np.NaN, inplace=True)\n",
    "res.dropna(subset=['total_esg_score', 'social_risk_score', 'controversy_level'], how='all', inplace=True)\n",
    "res.to_csv('yahoo_finance_sustainalytics.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
